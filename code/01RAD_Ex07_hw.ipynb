{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thomasula/practise/blob/main/code/01RAD_Ex07_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 01RAD Exercise 7 - team work\n",
        "\n",
        "Authors: name1, name 2, name3"
      ],
      "metadata": {
        "id": "zabFwaT_y0Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Description of the Assignment\n",
        "\n",
        "The dataset `Boston` contains a total of 506 records from towns in the suburbs of Boston, MA, USA. The data originates from the study by Harrison, D., and Rubinfeld, D.L. (1978), *Hedonic prices and the demand for clean air*, J. Environ. Economics and Management, 5, 81â€“102.\n",
        "\n",
        "The dataset includes 14 variables. The goal is to explore the influence of 13 of them on the median value of owner-occupied homes (`medv`). Below is a description of the variables:\n",
        "\n",
        "| Feature   | Description                                                                 |\n",
        "|-----------|-----------------------------------------------------------------------------|\n",
        "| `crim`    | Per capita crime rate by town                                              |\n",
        "| `zn`      | Proportion of residential land zoned for lots over 25,000 sq.ft            |\n",
        "| `indus`   | Proportion of non-retail business acres per town                           |\n",
        "| `chas`    | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)      |\n",
        "| `nox`     | Nitrogen oxides concentration (parts per 10 million)                       |\n",
        "| `rm`      | Average number of rooms per dwelling                                       |\n",
        "| `age`     | Proportion of owner-occupied units built prior to 1940                     |\n",
        "| `dis`     | Weighted mean of distances to five Boston employment centres               |\n",
        "| `rad`     | Index of accessibility to radial highways                                  |\n",
        "| `tax`     | Full-value property-tax rate per $10,000$                                   |\n",
        "| `ptratio` | Pupil-teacher ratio by  town    |                                            |\n",
        "| `black_tra`   | $1000\\left(\\text{black_pop} - 0.63\\right)^2$ where `black_pop` is the proportion of blacks by town       |\n",
        "| `lstat`   | Lower status of the population (percent)                                   |\n",
        "| `medv`    | Median value of owner-occupied homes in $1000s                             |\n",
        "\n",
        "---\n",
        "\n",
        "## Conditions and Scoring\n",
        "\n",
        "- Collaboration in the team is allowed and recommended.\n",
        "- This homework includes 14 questions.\n",
        "- Submit the homework in the corresponding `.ipynb` file, via MS Teams by the next week.\n",
        "---\n"
      ],
      "metadata": {
        "id": "rgsUsP_2QkIO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmgCFRDJyhcl"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRGg62JQ3kmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# URL for the Boston housing dataset\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
        "\n",
        "# Reading the dataset\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
        "\n",
        "# Processing the dataset into features and target\n",
        "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
        "target = raw_df.values[1::2, 2]\n",
        "\n",
        "# Column names\n",
        "columns = [\n",
        "    \"crim\", \"zn\", \"indus\", \"chas\", \"nox\", \"rm\", \"age\",\n",
        "    \"dis\", \"rad\", \"tax\", \"ptratio\", \"black_tra\", \"lstat\"\n",
        "]\n",
        "boston_df = pd.DataFrame(data, columns=columns)\n",
        "boston_df[\"medv\"] = target\n",
        "\n",
        "\n",
        "boston_df"
      ],
      "metadata": {
        "id": "u9bLMFl13B-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Exploratory and Graphical Analysis\n",
        "\n",
        "### Question 01\n",
        "\n",
        "- Check for missing values and verify the dimensions of the dataset.\n",
        "- Summarize the descriptive statistics of all variables.\n",
        "- Plot a histogram and density estimate for the response variable `medv`.\n",
        "- Examine the frequency table of `medv` values and discuss whether rounding, truncation, or other issues are present.\n",
        "- Remove measurements deemed unreliable and discuss what this implies for the response model.\n",
        "\n",
        "```python\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UuW64uar6L5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boston_df.info()\n",
        "boston_df.describe()\n",
        "print(boston_df.isnull().sum())  # Check for missing values\n",
        "print(boston_df.shape)"
      ],
      "metadata": {
        "id": "cfZ6HqPx6i4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(boston_df['medv'], kde=True, bins=30, color='blue', edgecolor='black')\n",
        "plt.title(\"Histogram and Density Estimate for MEDV\")\n",
        "plt.xlabel(\"MEDV\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GxEaRriUpxcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(boston_df['medv'].value_counts().sort_index())\n",
        "unreliable_measurements = boston_df[boston_df['medv'] == 50].index\n",
        "df_cleaned = boston_df.drop(unreliable_measurements)\n",
        "\n",
        "print(f\"Removed {len(unreliable_measurements)} unreliable measurements.\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df_cleaned['medv'], kde=True, bins=30, color='orange', edgecolor='black')\n",
        "plt.title(\"Histogram and Density Estimate for MEDV\")\n",
        "plt.xlabel(\"MEDV\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5u-tZ36qp3Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measurements with 'meadv' >= 50 removed. Model will be reliable for data with 'meadv' under 50 or only slightly above 50."
      ],
      "metadata": {
        "id": "LLea3rnmtVZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Regression Model: Median Price and Crime\n",
        "\n",
        "### Question 2\n",
        "\n",
        "- Build a simple linear regression model to examine if the crime rate (`crim`) affects the median value of homes (`medv`).\n",
        "- If there is an effect, determine how much the housing price decreases as the crime rate increases.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 3\n",
        "\n",
        "- Experiment with power and logarithmic transformations of the response variable (`medv`).\n",
        "- To find the optimal power transformation, plot the log-likelihood profile for the Box-Cox transformation and compare it with a logarithmic transformation.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 4\n",
        "\n",
        "- Based on the simple linear model and on the model with logarithmic transformations of the response variable, estimate the increase or decrease in housing prices for a one-unit change in the crime rate (`crim`).\n",
        "- Provide the correct interpretation from both models.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 5\n",
        "\n",
        "- Keep the logarithmic transformation of the response (`medv`) and try transforming the independent variable (`crim`).\n",
        "- Use techniques such as piecewise constant transformations, or polynomial transformations (quadratic and cubic).\n",
        "- Use information from plots such as Component-Residual Plots (Partial Residual Plots) and Partial Regression Plots to guide your transformations.\n",
        "- Discuss whether these models can be compared using an F-test. If applicable, perform the test and interpret the results.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 6\n",
        "\n",
        "- Select one of the previous models, justify your choice, and validate it using the appropriate hypothesis tests for residuals (normality, homoscedasticity, etc.).\n",
        "- Use diagnostic plots such as Q-Q plots, residuals vs. fitted values, and others to evaluate the model's assumptions.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "_EyeT_pK7LkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formula = 'medv ~ (crim)'\n",
        "\n",
        "# Fit an OLS model with interactions\n",
        "model = smf.ols(formula, data=df_cleaned).fit()\n",
        "\n",
        "# Display model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "ANrG30oBvTyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model with intercept can be interpreted as how the home price varies if there is higher crime rate from the mean home price. The R2 statistics is quite low, although for crude data and only one parameter it is not bad.\n",
        "The model shows how the median house price varies from the price when crime rate is 0, then for every unit the crime rate increases, house value drops by $400.\n"
      ],
      "metadata": {
        "id": "VfzZ-8clvZ0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['log_medv'] = np.log(df_cleaned['medv'])\n",
        "sns.histplot(df_cleaned['log_medv'], kde=True, bins=30, color='blue', edgecolor='black')\n",
        "plt.title(\"Histogram of Log-Transformed MEDV\")\n",
        "plt.xlabel(\"log(MEDV)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AMC9EHhGwGHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import boxcox\n",
        "from scipy.stats import boxcox_llf\n",
        "from scipy.stats import chi2\n",
        "\n",
        "df_cleaned['medv_positive'] = df_cleaned['medv'] + 1e-5\n",
        "boxcox_transformed, lambda_opt = boxcox(df_cleaned['medv_positive'])\n",
        "\n",
        "df_cleaned['boxcox_medv'] = boxcox_transformed\n",
        "\n",
        "print(f\"Optimal lambda for Box-Cox Transformation: {lambda_opt}\")\n",
        "\n",
        "lambda_values = np.linspace(-2, 2, 100)\n",
        "\n",
        "log_likelihoods = [boxcox_llf(lmb, df_cleaned['medv_positive']) for lmb in lambda_values]\n",
        "\n",
        "max_log_likelihood = max(log_likelihoods)\n",
        "\n",
        "threshold = max_log_likelihood - chi2.ppf(0.95, df=1) / 2\n",
        "\n",
        "lambda_conf_interval = lambda_values[\n",
        "    (log_likelihoods >= threshold)\n",
        "]\n",
        "\n",
        "lambda_low = min(lambda_conf_interval)\n",
        "lambda_high = max(lambda_conf_interval)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(lambda_values, log_likelihoods, label='Log-Likelihood')\n",
        "plt.axvline(lambda_opt, color='red', linestyle='--', label=f\"Optimal lambda = {lambda_opt:.2f}\")\n",
        "plt.axvline(lambda_low, color=\"green\", linestyle=\"--\", label=f\"95% CI Lower = {lambda_low:.2f}\")\n",
        "plt.axvline(lambda_high, color=\"blue\", linestyle=\"--\", label=f\"95% CI Upper = {lambda_high:.2f}\")\n",
        "plt.axhline(threshold, color=\"gray\", linestyle=\"--\", label=\"95% CI Threshold\")\n",
        "plt.title(\"Log-Likelihood Profile for Box-Cox Transformation\")\n",
        "plt.xlabel(\"Lambda\")\n",
        "plt.ylabel(\"Log-Likelihood\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LmPv4MjYxSqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(df_cleaned['log_medv'], kde=True, color='blue', bins=30)\n",
        "plt.title(\"Logarithmic Transformation (lambda = 0)\")\n",
        "plt.xlabel(\"log(MEDV)\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(df_cleaned['boxcox_medv'], kde=True, color='green', bins=30)\n",
        "plt.title(f\"Box-Cox Transformation (Optimal lambda = {lambda_opt:.2f})\")\n",
        "plt.xlabel(\"Box-Cox Transformed MEDV\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zhdM7KViyhK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lambda 0.5 was chosen as it is close to 0.4 and easier to apply and interpret"
      ],
      "metadata": {
        "id": "L7V4RUJFzVJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "X = sm.add_constant(df_cleaned['crim'])\n",
        "\n",
        "model_log = sm.OLS(df_cleaned['log_medv'], X).fit()\n",
        "\n",
        "model_boxcox = sm.OLS(df_cleaned['boxcox_medv'], X).fit()\n",
        "\n",
        "print(\"Logarithmic Transformation Model Summary:\")\n",
        "print(model_log.summary())\n",
        "\n",
        "print(f\"\\nBox-Cox Transformation with lambda = {lambda_opt:.2f} Model Summary:\")\n",
        "print(model_boxcox.summary())\n"
      ],
      "metadata": {
        "id": "44Zeu4V4zUgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(model_log.resid, kde=True, color='blue')\n",
        "plt.title(\"Residuals of Log-Transformed Model\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(model_boxcox.resid, kde=True, color='green')\n",
        "plt.title(\"Residuals of Box-Cox-Transformed Model\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "h7bJjeLb1EdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The price change under the model with just intercept and cirme rate, without data transformation was already explained. If we perform the logarithmic transformation, the crime rate coefficient has to be interpreted as a percentage change, that is calculated as: 100*(e^{beta_crime} - 1)\n",
        "because the values need to be transromed back using the exponential and then interpreted as proportional change"
      ],
      "metadata": {
        "id": "k3RQfNaC1byo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['crim_binned'] = pd.cut(df_cleaned['crim'], bins=[-np.inf, 1, 5, 10, np.inf], labels=['low', 'medium', 'high', 'very_high'])\n",
        "\n",
        "crim_dummies = pd.get_dummies(df_cleaned['crim_binned'], drop_first=True)\n",
        "X_piecewise = sm.add_constant(crim_dummies)\n",
        "\n",
        "model_piecewise = sm.OLS(df_cleaned['log_medv'], X_piecewise.astype(float)).fit()\n",
        "print(model_piecewise.summary())"
      ],
      "metadata": {
        "id": "vH_dtDIp1Leh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['crim_squared'] = df_cleaned['crim'] ** 2\n",
        "df_cleaned['crim_cubed'] = df_cleaned['crim'] ** 3\n",
        "\n",
        "X_poly2 = sm.add_constant(df_cleaned[['crim', 'crim_squared']])\n",
        "model_poly2 = sm.OLS(df_cleaned['log_medv'], X_poly2.astype(float)).fit()\n",
        "\n",
        "X_poly3 = sm.add_constant(df_cleaned[['crim', 'crim_squared', 'crim_cubed']])\n",
        "model_poly3 = sm.OLS(df_cleaned['log_medv'], X_poly3.astype(float)).fit()\n",
        "\n",
        "print(\"Quadratic Model Summary:\")\n",
        "print(model_poly2.summary())\n",
        "\n",
        "print(\"\\nCubic Model Summary:\")\n",
        "print(model_poly3.summary())"
      ],
      "metadata": {
        "id": "rpRT8Pzw4r_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even higher order terms seem to be statistically significant and R2 and even adj-R2 improved when moving to cubed variables. Other statistics remained rather same."
      ],
      "metadata": {
        "id": "5Rao3kLI6PIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.regressionplots import plot_ccpr\n",
        "from statsmodels.graphics.regressionplots import plot_partregress\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "plot_ccpr(model_poly2, 'crim', ax=ax)\n",
        "plt.title(\"Component-Residual Plot for crim (Quadratic Model)\")\n",
        "plt.show()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "plot_partregress('log_medv', 'crim', ['crim_squared'], data=df_cleaned, ax=ax)\n",
        "plt.title(\"Partial Regression Plot for crim (Quadratic Model)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q8wHeroc5Mvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: linear model is sufficient vs. the higher orders have large significance. Since the squared and cubed crime had good statistical significance it is suitable to compare them using the F statistics."
      ],
      "metadata": {
        "id": "eZAKAaJT6nUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare linear model to quadratic model\n",
        "f_test_result = model_poly2.compare_f_test(model)\n",
        "print(f\"F-test result (linear vs. quadratic): {f_test_result}\")\n",
        "\n",
        "# Compare linear to cubic model\n",
        "f_test_result2 = model_poly3.compare_f_test(model)\n",
        "print(f\"F-test result (quadratic vs. cubic): {f_test_result2}\")"
      ],
      "metadata": {
        "id": "MY5gzUEM5yM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "linear vs. quadratic results: F=288844.00, p=0.0, df=1.0, which indicatec that the cubic model fits significantly better than the linar one, however the improvement is not large going from quadratic to cubic model."
      ],
      "metadata": {
        "id": "zMJvrNhr7GXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare quadratic to cubic\n",
        "f_test_result3 = model_poly3.compare_f_test(model_poly2)\n",
        "print(f\"F-test result (quadratic vs. cubic): {f_test_result3}\")"
      ],
      "metadata": {
        "id": "X5V9hZS69tnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residuals vs. Fitted Values\n",
        "plt.figure(figsize=(8, 6))\n",
        "residuals_poly2 = model_poly2.resid\n",
        "sns.residplot(x=model_poly2.fittedvalues, y=residuals_poly2, lowess=True, line_kws={'color': 'red'})\n",
        "plt.title('Residuals for degree 2 model vs Fitted Values')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3_arueP3_hAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Residuals vs. Fitted Values\n",
        "plt.figure(figsize=(8, 6))\n",
        "residuals_poly3 = model_poly3.resid\n",
        "sns.residplot(x=model_poly3.fittedvalues, y=residuals_poly3, lowess=True, line_kws={'color': 'red'})\n",
        "plt.title('Residuals for degree 2 model vs Fitted Values')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Residuals')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "flW8ZU9gBHzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Q-Q plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "stats.probplot(residuals_poly2, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IVqiFFfDBRUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "\n",
        "# Q-Q plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "stats.probplot(residuals_poly3, dist=\"norm\", plot=plt)\n",
        "plt.title('Q-Q Plot')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NBXnDAriBaWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.diagnostic import het_breuschpagan\n",
        "\n",
        "X_quad_const = sm.add_constant(df_cleaned[['crim', 'crim_squared']])\n",
        "\n",
        "bp_test_stat, bp_test_p_value, _, _ = het_breuschpagan(residuals_poly2, X_quad_const)\n",
        "print(f\"Breusch-Pagan test statistic: {bp_test_stat}, p-value: {bp_test_p_value}\")\n",
        "\n",
        "X_quad_const = sm.add_constant(df_cleaned[['crim', 'crim_squared']])\n",
        "\n",
        "bp_test_stat, bp_test_p_value, _, _ = het_breuschpagan(residuals_poly3, X_quad_const)\n",
        "print(f\"Breusch-Pagan test statistic: {bp_test_stat}, p-value: {bp_test_p_value}\")"
      ],
      "metadata": {
        "id": "RZDroBDdBjNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By simply observing the plotted residuals one could see that there is no signifficant heteroskedacity. I added the Breusch-Pagan test here for completeness, where we failed to reject the null hypothesis that there is heteroskedacity. Durbin-Watson statistics for both models was around 0.8, which suggests some autocorrelation (which appears with the Durbin-Watson statistics being near 0)."
      ],
      "metadata": {
        "id": "7MYm1owDChqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on D-W statistics, QQ plots and residual plots being largely the same with the quadratic and the cubic model and seeing no significant improvement taking the cubic model... R2 didn't improve much and the F-test suggested that although there is statistical signifficance in taking the cubic model, the improvement is not worth it. I would pick the quadratic model, since the interpretation is more straight forward and it is simpler and also offers good precision."
      ],
      "metadata": {
        "id": "3d1-7TN6DzyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Multivariate Regression Model\n",
        "\n",
        "### Question 7\n",
        "\n",
        "- Build a multivariate linear regression model with a logarithmic transformation of the response (`medv`).\n",
        "- Explore relationships between housing prices and other independent variables in an additive model (no interactions).\n",
        "- Use criteria such as AIC, BIC, $ R^2 $, and F-statistics to select the best model.\n",
        "- Investigate whether the relationship between `crim` and `medv` can be explained by other variables, such as proximity to highways or pollution levels.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 8\n",
        "\n",
        "- Incorporate `crim` (crime rate) into the final model and compare how its influence on the median housing price differs from the simple regression model with a logarithmic transformation of the response (from Question 4).\n",
        "- Estimate the reduction in median housing price for a one-unit increase in the crime rate per 1,000 residents.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 9\n",
        "\n",
        "- Present your final predictive model for `medv` and discuss the key parameters such as $ R^2 $, $ \\sigma $, and F-statistics.\n",
        "- Compare the final model with the simple linear model from Question 6. Discuss how these parameters have changed and whether this change was expected.\n",
        "- Validate the model both graphically and using hypothesis tests.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 10\n",
        "\n",
        "- Based on your final model, answer whether reducing the crime rate in an area would lead to an increase in housing prices in that area.\n",
        "- Provide an explanation based on your findings.\n"
      ],
      "metadata": {
        "id": "INE7xTEg7NCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Investigating the Transformation of the `black_tra` Variable\n",
        "\n",
        "<!--\n",
        "# Add a new variable `black_pop` representing the proportion of Black population\n",
        "boston_df[\"black_pop\"] = 0.63 - np.sqrt(boston_df[\"black_tra\"] / 1000)\n",
        " -->"
      ],
      "metadata": {
        "id": "Nn3vN2LYJAV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Motivation of this section\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "# Load dataset\n",
        "boston_data = load_boston()"
      ],
      "metadata": {
        "id": "Ve9Kp3kTJG0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Question 11: Compare Coefficients in Simple Models\n",
        "\n",
        "Investigate, if the transformation of `black_pop` into `black_tra` was  misleading and suggestive. Add new variable `black_pop` into the data frame by inverse of orginal transformation.\n",
        "\n",
        "- Build two separate simple linear regression models:\n",
        "  1. Predicting `medv` using `black_tra`.\n",
        "  2. Predicting `medv` using `black_pop`.\n",
        "- Compare the coefficients from both models and interpret the differences.\n",
        "- Discuss whether the transformation of `black_tra` appears to exaggerate or diminish its relationship with `medv`.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 12: Stepwise Regression with `black_tra`\n",
        "\n",
        "- Perform stepwise regression starting with all independent variables, including `black_tra`, as predictors of `medv`.\n",
        "- Evaluate whether `black_tra` remains significant in the final model after stepwise variable selection.\n",
        "- Discuss whether its significance changes when considered alongside other predictors.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 13: Stepwise Regression with `black_pop`\n",
        "\n",
        "- Repeat the stepwise regression from Question 12, but this time replace `black_tra` with `black_pop`.\n",
        "- Evaluate whether `black_pop` remains significant in the final model.\n",
        "- Compare its significance to that of `black_tra` from Question 12.\n",
        "\n",
        "---\n",
        "\n",
        "### Question 14: Impact on Predictions\n",
        "\n",
        "- For both the models from Questions 12 and 13 (stepwise regression with `black_tra` and `black_pop`), compare their predictions for `medv`.\n",
        "- Specifically:\n",
        "  1. Calculate predictions for a range of values of `black_tra` and `black_pop`.\n",
        "  2. Plot the predictions and interpret whether the two variables result in substantially different predicted values.\n",
        "- Discuss whether the transformed variable (`black_tra`) or its proportion counterpart (`black_pop`) leads to any noticeable bias or distortion in predictions.\n"
      ],
      "metadata": {
        "id": "u5dQeJXeJF-z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d2cweQYtziLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z17yMfNC7JA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}